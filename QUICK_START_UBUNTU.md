# Ubuntu æœåŠ¡å™¨å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ ä¸€é”®å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/advimman/lama.git
cd lama

# 2. è¿è¡Œåˆå§‹åŒ–è„šæœ¬
chmod +x init_ubuntu_server.sh
./init_ubuntu_server.sh

# 3. é‡æ–°åŠ è½½é…ç½®
source ~/.bashrc

# 4. æ¿€æ´»ç¯å¢ƒ
conda activate lama
```

## âœ… éªŒè¯å®‰è£…

```bash
conda activate lama
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import cv2; print(f'OpenCV: {cv2.__version__}')"
```

## ğŸ“¥ ä¸‹è½½æ¨¡å‹

```bash
cd lama
curl -LJO https://huggingface.co/smartywu/big-lama/resolve/main/big-lama.zip
unzip big-lama.zip
```

## ğŸ¯ è¿è¡Œæ¨ç†

```bash
cd lama
export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)
conda activate lama

python3 bin/predict.py \
    model.path=$(pwd)/big-lama \
    indir=$(pwd)/LaMa_test_images \
    outdir=$(pwd)/output
```

## ğŸ“‹ å®‰è£…æ¸…å•

- [ ] ç³»ç»Ÿæ›´æ–°å®Œæˆ
- [ ] Miniconda å·²å®‰è£…
- [ ] conda ç¯å¢ƒ `lama` å·²åˆ›å»º
- [ ] PyTorch å·²å®‰è£…
- [ ] é¡¹ç›®ä¾èµ–å·²å®‰è£…
- [ ] é¢„è®­ç»ƒæ¨¡å‹å·²ä¸‹è½½
- [ ] ç¯å¢ƒå˜é‡å·²è®¾ç½®

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate lama

# è®¾ç½®ç¯å¢ƒå˜é‡
export TORCH_HOME=$(pwd)
export PYTHONPATH=$(pwd)

# æ£€æŸ¥ GPU
nvidia-smi

# æ£€æŸ¥ CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- å®Œæ•´å®‰è£…æŒ‡å—ï¼š[INSTALL_UBUNTU.md](INSTALL_UBUNTU.md)
- æ•…éšœæ’æŸ¥ï¼š[TROUBLESHOOTING.md](TROUBLESHOOTING.md)
- é¡¹ç›®è¯´æ˜ï¼š[README.md](README.md)

